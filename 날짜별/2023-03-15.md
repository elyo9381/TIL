
----
## SPOF ( Single Point of Failure )

동작하지 않으면 전체 시스템이 중단되는 요소를 말한다.

- 데이터베이스 서버 
- api 서버

----
## TPS / RPS

![[tps 그림.png]]

TPS , RPS는 성능을 나타내는 하나의 지표 입니다. 
정보 시스템에서 좋은 성능은 처리량(Throughput) 과 응답시간(Response Time)입니다.
그렇다면 이둘을 어떻게 측정할 수 있을까요 ? 
한마디로 정의하면 서버가 빨리빨리 처리하면 됩니다. !


### TPS : Trancsaction per second
프로그램에서 ==초당 트랜잭션 처리수를 TPS== 라고 부릅니다. 
TPS는 Throughput의 하나의 단위가 될수 있습니다. (Throughput의 단위는 한번 검색해보시길 ... ~)

그래서 성능의 지표로 해석 됩니다. tps 및 rps를 올리기 위해서 ==낮은 레이턴시==와 ==빠른 처리시간== 받쳐줘야한다. 
- 낮은 레이턴시
- 빠른 처리시간
을 수행하긴 위해서는 다양한 기술과 원리를 알아야 합니다.
이에 대해서는 포스트를 게시 하도록 하겠습니다.

>[! tip]
>	최대 tps = 1개 커넥션의 초당 처리 요청 갯수 * 동시 커넥션 개수 
>	동시 커넥션 개수 = 최대 tps / 1개 커넥션의 초당 요청 처리 갯수
>	  		 	 = 최대 tps / (1초 / 쿼리 실행시간)


### Saturation Point

성능 테스트 즉 자원의 최대한의 범위까지 수행가능 한 능력을 측정하는것이 TPS라고 했습니다.
TPS가 계속 오르게 되면 일정 TPS에서 멈추게 되어 있습니다. 
이지점을 Saturation Point 라고 합니다. 

Saturation Point(임계점) 가 넘어가면 자동으로 scale-out이 되도록 진행되어야 할 것 같습니다. 
~~Saturation Point가 넘어가면 대기열 발생할는 트리거가 될 수도 있겠습니다.~~ 


### RPS : Request Per Second
초당 요청 처리수 

>[! tip]
> auto scaling 을 통해서 성능을 높일수 있다. 하지만 최적화 되지 않은 auto scaling은 비효율적인 비용이 들어간다.

----
## 블로킹 포인트 

### DB ( 서버 처리시간 )
DB 성능 향상 기법을 통해서 성능을 향상시켜야한다. 
explain을 통해서 분석이 들어가지 않을까 싶다. 

###  **쓰레드풀 / 커넥션 풀 최적화**
- 커넥션 대기 시간 : connectionTimeout  설정
- 커넥션 최대 유지 시간  : maxLifetime  설정
	- 네크워크나 DB의 관련 설정 값보다 작은 값 사용
		- ex) 네트워크 장비의 최대 TCP 커넥션 유지 시간
- 커넥션 최대 유지 시간  : keepaliveTime  설정
	- 네크워크나 DB의 관련 설정 값보다 작은 값 사용
		- ex) DB 미 활동 커넥션 대기 시간 
	- 유휴 커넥션 확인

### DB 성능 향상을 위한 고려 
-  Query 튜닝
	- index
	- 정규화 및 비정규화 
-  Cache 이용
-  장비빨(~~금융 치료, Money Swag~~)
    -   Hardware upgrade (Scale Up)
    -   DB Replication -> 부하 분산
        -   Primary (DB 쓰기)
        -   Replica (DB 읽기)

### 서버
불필요한 객체생성 , 코드리팩터링을 통해서 latency를 줄여야한다. 
지연대기 시간을 줄여야한다. 


1. 외부 서비스 Latency 줄이기  ( 서버 처리시간 )
-   외부 서비스 API 호출 응답 시간 증가는 곧 우리 서버의 처리 시간 증가를 의미
-   개선 방법
    -   Cache 사용
    -   외부 서비스 API 호출 제거
        -   Messaging 을 이용한 방법(Kafka, RabbitMQ 등)

2. 데이터 집계 시간 줄이기  ( 서버 처리시간 )
-   미리 계산하여 Caching or DB 에 저장
-   Example
    -   좋아요 수
    -   리뷰 수

3. 요청대기 Latency 줄이기 
-   세가지 방식 고려
    -   응답 크기 줄이기
        -   응답 압축
        -   이미지 파일 크기 줄이기, 이미지 해상도 낮추기
    -   트래픽 분리하기
        -   이미지와 같은 정적 파일을 CDN(Content Delivery Network) 을 통해 제공
        -   CDN 은 이미지 등과 같은 정적 파일 전송에 특화된 서비스이기에 CDN 들은 대역폭 자체가 크다
    -   대역폭 늘리기
        -   비용 측면에서 CDN(Content Delivery Network) 가 유리하다
        - **S3**
        - **Cloudflare**

4. 외부 서비스 간에 연동 latency 줄이기 
	1. 내부 비동기 로직 
		- 고민거리 
			- 트랜잭션 처리 
			- 서버 재시작시 작업 유실
			- 외부 연동 실패시 재처리 
			- 쓰레드 풀 크기
			-> 트랜잭션 처리후에 진행토록 함
		- 재처리 필요성이 낮은 외부 연동에 적합
	2. DB 사용
		- 누락이 없어야 할 연동에 적합 ex) 로그인 포인트 적립
	3. messageQueue 사용
		- kafka, rabbitMq에 전송하고 이를 다른 모듈(책임을 갖는) 이 처리한다. 
		- 데이터 유실 가능성 존재 
		- 수동으로 transaction 처리가 필요 

5. 동기로 방식으로 외부 서비스 호출할 때 외부 서비스 장애 영향을 덜 받는 방법
	1. 타임아웃
		- 오래 대기하는것보다 빨리 에러를 발생시키자 
		- 외부 api 호출시 두 개 타임 아웃 설정
			- 연결 시간 타임 아웃 ( 1 ~ 5초 이내로 설정)
			- 응답 시간 타임 아웃 ( 1 ~ 3초)
			- 외부 서비스 특징에 따라 길게 주기도 함
		- **HTTP 커넥션 풀 사용실 추가 타임 아웃 설정 (1~5초 이내)** 
	2. 벌크 헤드 (Bulkhead) - 격벽
		- 특정 서비서 장애 -> 전체 영향
			- A,B,C연동에 대해 커넥션풀을 공유할때
			1. A 서비스의 장애로 응답 시간 지연 발생
			2. 풀에 남은 유휴 커넥션이 감소
			3. 풀에서 커넥션을 구하는 대기 시간이 증가
			4. B,C는 자연스럽게 대기 
		- 기능 / 서비스 / 클라이언트 마다 자원 사용 분리
			- 한 기능 /서비스 장애가 다른 기능/서비스에 주는 영향 최소화
			- ==각각의 커넥션 풀 설정 ( 커넥션풀 공유 X )==
	3. 서킷 브레이커 (Circuit Breaker)
			외부 서비스가 계속 에러가 지속이 되면 내 서비스도 에러가 발생하는 상황 발생 
			 장애는 어쩔수 없지만, 응답 시간 느려짐, 처리량 감소가 진행됨
			 이럴때 서킷 브레이커를 사용
		- 오류지속시 일정 시간동안 기능 실행을 차단함 ( fail fast )
		1. 외부 서비스가 에러 발생시 서킷브레이커를 달았던 코드가 실패를 인지 
		2. 특정 트리거 달성시 서킷 브레이커를 고객에서 에러를 반환


- GC 모니터링
- 코드 재활용을 통한 리팩터링 


---
## 성능테스트

### 부하 테스트 
- 병목 현상을 확인하고 목표치까지 개선하는것이 목적

### 스트레스 테스트 
- 과부하 상태에서 어떻게 동작하는지 확인하고 개선하는 것이 목적


### JMeter

### nGrinder

---

## Sharding
- O(1)

---

## socket

SSE 는 양방향 통신이 안된다. 
- 간단한 알람 
- STOMP -> pub/sub



1. 대기열 진입 ( 소켓 )
2. (대기열 , 작업열 )배치 기능
3. 대기열 정보 스케줄링  기능
4. 대기열 모니터링 기능


![[Pasted image 20230315211226.png]]